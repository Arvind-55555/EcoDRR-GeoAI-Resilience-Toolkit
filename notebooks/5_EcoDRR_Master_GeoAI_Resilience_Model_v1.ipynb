{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b151269",
      "metadata": {
        "id": "1b151269"
      },
      "source": [
        "# EcoDRR — Master GeoAI Resilience Model (v1)\n",
        "Full end-to-end notebook: GEE preproc, patch extraction, U-Net training & inference, DEM/hydrology, NDVI Δ, habitat quality, and DRR risk mapping. Use in Colab with GEE auth."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "lyHd_4XnemjK"
      },
      "id": "lyHd_4XnemjK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d76578a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "d76578a8",
        "outputId": "0d0667fe-3b99-4a7e-f593-6bd1e794a34b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Core libs loaded\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from rasterio.enums import Resampling\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "print('Core libs loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "198ed46d",
      "metadata": {
        "id": "198ed46d"
      },
      "source": [
        "## 1. GEE — authenticate & fetch\n",
        "This section shows how to fetch Sentinel-2 composites, CHIRPS and NASADEM from Earth Engine. Run in Colab after ee.Authenticate() and ee.Initialize()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5bbd81c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5bbd81c9",
        "outputId": "a8f28ec3-a226-4801-fbc3-2370a18eba2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earth Engine available\n"
          ]
        }
      ],
      "source": [
        "# Earth Engine block\n",
        "try:\n",
        "    import ee, geemap\n",
        "    print('Earth Engine available')\n",
        "except Exception as e:\n",
        "    print('GEE not available:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37f2b9d",
      "metadata": {
        "id": "b37f2b9d"
      },
      "source": [
        "## 2. Local TIFF loader and preprocessing\n",
        "Load `/content/data/sent_rgb.tif` and `/content/data/sent_ndvi.tif`, downsample and crop for patching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbc57c32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bbc57c32",
        "outputId": "a3225858-b5b3-4e09-b3c3-436faa752c25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared combined array (4, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "def load_downsample(path, max_dim=256, bands=None):\n",
        "    with rasterio.open(path) as src:\n",
        "        if bands is None: bands = src.indexes\n",
        "        w,h = src.width, src.height\n",
        "        scale = max(1, max(w,h)/max_dim)\n",
        "        out_w,out_h = int(w/scale), int(h/scale)\n",
        "        data = src.read(bands, out_shape=(len(bands),out_h,out_w), resampling=Resampling.bilinear)\n",
        "    return data\n",
        "\n",
        "def crop_center(data, win=128):\n",
        "    _,H,W = data.shape\n",
        "    cy,cx = H//2, W//2\n",
        "    return data[:, cy-win//2:cy+win//2, cx-win//2:cx+win//2]\n",
        "\n",
        "rgb_path='/content/data/sent_rgb.tif'\n",
        "ndvi_path='/content/data/sent_ndvi.tif'\n",
        "if os.path.exists(rgb_path) and os.path.exists(ndvi_path):\n",
        "    rgb = load_downsample(rgb_path,256,[1,2,3])\n",
        "    ndv = load_downsample(ndvi_path,256,[1])\n",
        "    rgb128 = crop_center(rgb,128)\n",
        "    ndv128 = crop_center(ndv,128)\n",
        "    combined = np.concatenate([rgb128.astype('float32'), ndv128.astype('float32')], axis=0)\n",
        "    print('Prepared combined array', combined.shape)\n",
        "else:\n",
        "    print('Missing sent_rgb.tif or sent_ndvi.tif in /content/data — please export from GEE or upload')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77a915e3",
      "metadata": {
        "id": "77a915e3"
      },
      "source": [
        "## 3. Patch extraction, U-Net training & inference (light)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eb3a42da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "eb3a42da",
        "outputId": "6368418a-1847-4467-c1b2-255fe1fec98c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patches saved (16, 4, 32, 32)\n",
            "Ep 1 loss 1.2979334592819214\n",
            "Ep 2 loss 1.281512200832367\n",
            "Ep 3 loss 1.2609952986240387\n",
            "Model trained and saved\n"
          ]
        }
      ],
      "source": [
        "def extract_patches(image, ps=32):\n",
        "    b,H,W = image.shape\n",
        "    patches=[]\n",
        "    for y in range(0,H-ps+1,ps):\n",
        "        for x in range(0,W-ps+1,ps):\n",
        "            patches.append(image[:, y:y+ps, x:x+ps])\n",
        "    return np.stack(patches,0)\n",
        "\n",
        "if 'combined' in globals():\n",
        "    patches = extract_patches(combined,32)\n",
        "    np.savez_compressed('/content/data/patches_rgb_ndvi.npz', patches=patches)\n",
        "    print('Patches saved', patches.shape)\n",
        "\n",
        "# Tiny UNet definition\n",
        "class TinyUNet(nn.Module):\n",
        "    def __init__(self, inc, cls):\n",
        "        super().__init__()\n",
        "        self.e1=nn.Sequential(nn.Conv2d(inc,16,3,padding=1),nn.ReLU(), nn.Conv2d(16,16,3,padding=1), nn.ReLU())\n",
        "        self.p=nn.MaxPool2d(2)\n",
        "        self.e2=nn.Sequential(nn.Conv2d(16,32,3,padding=1),nn.ReLU(), nn.Conv2d(32,32,3,padding=1), nn.ReLU())\n",
        "        self.u=nn.ConvTranspose2d(32,16,2,stride=2)\n",
        "        self.d1=nn.Sequential(nn.Conv2d(32,16,3,padding=1),nn.ReLU(), nn.Conv2d(16,16,3,padding=1), nn.ReLU())\n",
        "        self.out=nn.Conv2d(16,cls,1)\n",
        "    def forward(self,x):\n",
        "        e1=self.e1(x); e2=self.e2(self.p(e1)); u=self.u(e2); d=self.d1(torch.cat([u,e1],1)); return self.out(d)\n",
        "\n",
        "# Lightweight training if patches exist\n",
        "if os.path.exists('/content/data/patches_rgb_ndvi.npz'):\n",
        "    data = np.load('/content/data/patches_rgb_ndvi.npz')['patches']\n",
        "    X = data.astype('float32'); X = X/(X.max()+1e-9)\n",
        "    ndv = X[:,3:4]; bright = X[:,:3].mean(1)\n",
        "    labels = np.zeros((X.shape[0],32,32), dtype=np.int64)\n",
        "    labels[(ndv[:,0]>0.25)] = 1\n",
        "    labels[(ndv[:,0]<=0.25)&(bright>0.4)] = 2\n",
        "    labels[(ndv[:,0]<=0.25)&(bright<=0.4)] = 3\n",
        "    ds = TensorDataset(torch.tensor(X), torch.tensor(labels))\n",
        "    dl = DataLoader(ds, batch_size=4, shuffle=True)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = TinyUNet(4,4).to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for ep in range(3):\n",
        "        tot=0\n",
        "        for xb,yb in dl:\n",
        "            xb,yb=xb.to(device),yb.to(device)\n",
        "            opt.zero_grad(); out=model(xb); loss=loss_fn(out,yb); loss.backward(); opt.step(); tot+=loss.item()\n",
        "        print('Ep', ep+1, 'loss', tot/len(dl))\n",
        "    os.makedirs('/content/data/models', exist_ok=True)\n",
        "    torch.save(model.state_dict(), '/content/data/models/tiny_unet_trained.pth')\n",
        "    print('Model trained and saved')\n",
        "else:\n",
        "    print('No patches found for training — run preprocessing or upload patches')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e74ff852",
      "metadata": {
        "id": "e74ff852"
      },
      "source": [
        "End of Master notebook; use specific sections to run full experiments."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}